import gc
import logging
import time
from typing import Any

import datasets
import torch
from hivemind.dht import DHT
from hivemind.utils import get_dht_time
from trl import GRPOConfig, GRPOTrainer

from hivemind_exp.dht_utils import (
    ROUND_STAGE_NUMBER_KEY,
    get_dht_value,
    get_round_and_stage,
    leaderboard_key,
    node_outputs_key,
    rewards_key,
)
from hivemind_exp.hivemind_utils import HivemindNode, StageData
from hivemind_exp.name_utils import get_name_from_peer_id


class HivemindGRPOTrainer:
    """
    åŸºäºHivemindçš„GRPOè®­ç»ƒå™¨
    
    è¿™æ˜¯GRPOTrainerçš„å­ç±»ï¼Œé€šè¿‡å°†ä¸­é—´ç»“æœå‘å¸ƒåˆ°è¿æ¥çš„Hivemind DHTç½‘ç»œæ¥å®ç°å¤šé˜¶æ®µGRPOè®­ç»ƒã€‚
    å®ƒæ˜¯åˆ†å¸ƒå¼è®­ç»ƒç³»ç»Ÿä¸­çš„æ ¸å¿ƒç»„ä»¶ï¼Œè´Ÿè´£è®­ç»ƒæ¨¡å‹å¹¶ä¸å…¶ä»–èŠ‚ç‚¹å…±äº«ç»“æœã€‚
    """

    class PublishingGRPOTrainer(GRPOTrainer):
        """
        è´Ÿè´£å°†è®­ç»ƒç»“æœå‘å¸ƒåˆ°DHTç½‘ç»œçš„GRPOè®­ç»ƒå™¨
        
        è¿™ä¸ªå†…éƒ¨ç±»ç»§æ‰¿è‡ªGRPOTrainerï¼Œæ‰©å±•äº†å…¶åŠŸèƒ½ä»¥å°†è®­ç»ƒè¿‡ç¨‹ä¸­çš„è¾“å‡ºå’Œå¥–åŠ±å‘å¸ƒåˆ°DHTç½‘ç»œï¼Œ
        ä½¿å¾—å…¶ä»–èŠ‚ç‚¹å¯ä»¥è·å–è¿™äº›ä¿¡æ¯ã€‚å®ƒæ˜¯åˆ†å¸ƒå¼è®­ç»ƒç³»ç»Ÿä¸­çš„ç½‘ç»œé€šä¿¡æ ¸å¿ƒã€‚
        """
        def __init__(
            self,
            node: HivemindNode,
            dht: DHT,
            tokenizer,
            logger,
            **kwargs,
        ):
            """
            åˆå§‹åŒ–PublishingGRPOTrainer
            
            å‚æ•°:
                node: HivemindèŠ‚ç‚¹å®ä¾‹
                dht: DHTç½‘ç»œå®ä¾‹ï¼Œç”¨äºä¸åˆ†å¸ƒå¼å“ˆå¸Œè¡¨äº¤äº’
                tokenizer: åˆ†è¯å™¨ï¼Œç”¨äºå¤„ç†æ–‡æœ¬
                logger: æ—¥å¿—è®°å½•å™¨
                **kwargs: ä¼ é€’ç»™çˆ¶ç±»GRPOTrainerçš„å…¶ä»–å‚æ•°
            """
            self.node = node  # HivemindèŠ‚ç‚¹
            self.dht = dht    # DHTç½‘ç»œå®ä¾‹
            self.logger = logger  # æ—¥å¿—è®°å½•å™¨
            self.stage_rewards = 15.0  # å½“å‰é˜¶æ®µçš„ç´¯è®¡å¥–åŠ±
            super().__init__(processing_class=tokenizer, **kwargs)

        def publish_leaderboard(self):
            """
            å‘å¸ƒæ’è¡Œæ¦œåˆ°DHTç½‘ç»œ
            
            è¿™ä¸ªæ–¹æ³•ç”±åè°ƒè€…èŠ‚ç‚¹è°ƒç”¨ï¼Œç”¨äºæ”¶é›†æ‰€æœ‰èŠ‚ç‚¹çš„å¥–åŠ±ä¿¡æ¯ï¼Œ
            ç”Ÿæˆæ’åºåçš„æ’è¡Œæ¦œï¼Œå¹¶å°†å…¶å‘å¸ƒåˆ°DHTç½‘ç»œä¾›æ‰€æœ‰èŠ‚ç‚¹æŸ¥çœ‹ã€‚
            è¿™æ˜¯ç½‘ç»œé€šä¿¡çš„å…³é”®éƒ¨åˆ†ï¼Œå®ç°äº†èŠ‚ç‚¹é—´çš„ç«äº‰å’Œåä½œæœºåˆ¶ã€‚
            """
            r, s = self.node.round_num, self.node.stage_num
            # ä»DHTç½‘ç»œè·å–å½“å‰è½®æ¬¡å’Œé˜¶æ®µçš„æ‰€æœ‰èŠ‚ç‚¹å¥–åŠ±
            curr_rewards: dict[str, Any] | None = get_dht_value(
                self.dht, key=rewards_key(r, s), latest=True
            )
            if curr_rewards:
                # åˆ›å»ºæŒ‰å¥–åŠ±å€¼é™åºæ’åºçš„(èŠ‚ç‚¹é”®, å¥–åŠ±)å¯¹åˆ—è¡¨
                leaderboard = list(
                    sorted(
                        curr_rewards.items(), key=lambda t: (t[1], t[0]), reverse=True
                    )
                )
                # å°†æ’è¡Œæ¦œå­˜å‚¨åˆ°DHTç½‘ç»œ
                # è¿™æ˜¯ä¸€ä¸ªç½‘ç»œé€šä¿¡æ“ä½œï¼Œå°†æ•°æ®å‘å¸ƒåˆ°åˆ†å¸ƒå¼ç½‘ç»œ
                self.dht.store(
                    key=leaderboard_key(r, s),
                    value=leaderboard,
                    expiration_time=get_dht_time() + self.node.out_expiration,
                )
            else:
                self.logger.info(f"æ— æ³•è·å–è½®æ¬¡ {r} é˜¶æ®µ {s - 1} çš„å¥–åŠ±æ•°æ®")

        def compute_loss(self, model, inputs, *args, **kwargs):
            """
            è®¡ç®—æ¨¡å‹æŸå¤±å¹¶å°†è¾“å‡ºå’Œå¥–åŠ±å‘å¸ƒåˆ°DHTç½‘ç»œ
            
            è¿™ä¸ªæ–¹æ³•é‡å†™äº†çˆ¶ç±»çš„compute_lossæ–¹æ³•ï¼Œåœ¨è®¡ç®—æŸå¤±çš„åŒæ—¶ï¼Œ
            å°†æ¨¡å‹çš„è¾“å‡ºå’Œè·å¾—çš„å¥–åŠ±å‘å¸ƒåˆ°DHTç½‘ç»œï¼Œä½¿å…¶ä»–èŠ‚ç‚¹å¯ä»¥è·å–è¿™äº›ä¿¡æ¯ã€‚
            è¿™æ˜¯åˆ†å¸ƒå¼è®­ç»ƒç³»ç»Ÿä¸­çš„æ ¸å¿ƒç½‘ç»œé€šä¿¡æ“ä½œã€‚
            
            å‚æ•°:
                model: æ¨¡å‹å®ä¾‹
                inputs: è¾“å…¥æ•°æ®
                *args, **kwargs: ä¼ é€’ç»™çˆ¶ç±»æ–¹æ³•çš„å…¶ä»–å‚æ•°
                
            è¿”å›:
                è®¡ç®—çš„æŸå¤±å€¼
            """
            # è°ƒç”¨çˆ¶ç±»æ–¹æ³•è®¡ç®—æŸå¤±
            loss = super().compute_loss(model, inputs, *args, **kwargs)
            
            # å¥–åŠ±å‡½æ•°å¿…é¡»ä¿å­˜node.outputså’Œnode.rewardsï¼
            # è¿™é‡Œçš„ä»£ç è´Ÿè´£åœ¨é€‚å½“çš„æ—¶æœºå°†æ•°æ®å‘å¸ƒåˆ°DHTç½‘ç»œ
            
            # è·å–é—®é¢˜å’Œè¾“å‡ºå€¼
            question = self.node.outputs["question"]
            value = (time.time(), self.node.outputs)
            
            # å°†è¾“å‡ºå­˜å‚¨åˆ°DHTç½‘ç»œ
            # è¿™æ˜¯ä¸€ä¸ªç½‘ç»œé€šä¿¡æ“ä½œï¼Œå°†èŠ‚ç‚¹çš„è¾“å‡ºå‘å¸ƒåˆ°åˆ†å¸ƒå¼ç½‘ç»œ
            self.dht.store(
                key=node_outputs_key(self.node),  # ä½¿ç”¨èŠ‚ç‚¹ç‰¹å®šçš„è¾“å‡ºé”®
                subkey=question,                  # ä½¿ç”¨é—®é¢˜ä½œä¸ºå­é”®
                value=value,                      # å­˜å‚¨(æ—¶é—´æˆ³, è¾“å‡º)å…ƒç»„
                expiration_time=get_dht_time() + self.node.out_expiration,  # è®¾ç½®è¿‡æœŸæ—¶é—´
            )
            
            # åŒæ—¶å°†è¾“å‡ºå­˜å…¥æœ¬åœ°ç¼“å­˜
            self.node.put_stage_outputs(
                self.node.round_num, self.node.stage_num, question, value
            )

            # ç´¯åŠ æœ€æ–°çš„å¥–åŠ±å€¼
            self.stage_rewards += sum(self.node.rewards)
            self.logger.info(
                f"          âœ…âœ…âœ…âœ…âœ…âœ…------âœ…âœ…âœ…âœ…âœ… "
            )
            self.logger.info(
                f" key ------>> å½“å‰keyå€¼ä¸º {rewards_key(self.node.round_num, self.node.stage_num)}"
            )
            self.logger.info(
                f" subkey ------>> å½“å‰subkeyå€¼ä¸º {self.node.key}"
            )
            self.logger.info(
                f" value ------>> å½“å‰valueå€¼ä¸º {self.stage_rewards}"
            )
            self.logger.info(
                f" expiration_time ------>> å½“å‰expiration_timeå€¼ä¸º {get_dht_time() + self.node.out_expiration}"
            )
            self.logger.info(
                f"          âœ…âœ…âœ…âœ…âœ…âœ…------âœ…âœ…âœ…âœ…âœ… "
            )
            # å°†ç´¯è®¡å¥–åŠ±å­˜å‚¨åˆ°DHTç½‘ç»œ
            # è¿™æ˜¯å¦ä¸€ä¸ªç½‘ç»œé€šä¿¡æ“ä½œï¼Œå°†èŠ‚ç‚¹çš„å¥–åŠ±å‘å¸ƒåˆ°åˆ†å¸ƒå¼ç½‘ç»œ
            self.dht.store(
                key=rewards_key(self.node.round_num, self.node.stage_num),  # ä½¿ç”¨å½“å‰è½®æ¬¡å’Œé˜¶æ®µçš„å¥–åŠ±é”®
                subkey=self.node.key,                                      # ä½¿ç”¨èŠ‚ç‚¹é”®ä½œä¸ºå­é”®
                value=self.stage_rewards,                                  # å­˜å‚¨ç´¯è®¡å¥–åŠ±å€¼
                expiration_time=get_dht_time() + self.node.out_expiration,  # è®¾ç½®è¿‡æœŸæ—¶é—´
            )
            
            # å¦‚æœæ˜¯åè°ƒè€…èŠ‚ç‚¹ï¼Œåˆ™å‘å¸ƒæ’è¡Œæ¦œ
            if self.node.is_coordinator:
                self.publish_leaderboard()

            return loss

    def __init__(
        self,
        node: HivemindNode,
        dht: DHT,
        stage_data: StageData,
        config: GRPOConfig,
        model,
        tokenizer,
        log_tag=None,
        **kwargs,
    ):
        # The single coordinator is responsible for incrementing round + stage numbers.
        # TODO(lou): Allow ability to choose different coordinators?
        self.node = node
        self.dht = dht

        self.stage_data = stage_data

        self.config = config
        assert self.config.output_dir
        self.config.output_dir += f"-{get_name_from_peer_id(self.node.key, True)}"  # TODO: Add animal name to save path in more appropriate spot
        self.model = model
        self.tokenizer = tokenizer
        if tokenizer.pad_token is None:
            tokenizer.pad_token = tokenizer.eos_token

        if not log_tag:
            log_tag = self.node.key

        self.logger = logging.getLogger(f"{__name__}:{log_tag}")

    def wait_for(self, result_fn=lambda: None, interval=10, timeout=30):
        """
        ç­‰å¾…å‡½æ•°æ‰§è¡Œç›´åˆ°è¶…æ—¶æˆ–è¿”å›éNoneç»“æœ
        
        è¿™ä¸ªè¾…åŠ©æ–¹æ³•ç”¨äºç­‰å¾…æŸä¸ªæ“ä½œå®Œæˆï¼Œæ¯”å¦‚ç­‰å¾…DHTç½‘ç»œä¸­çš„æ•°æ®å¯ç”¨ã€‚
        å®ƒä¼šå®šæœŸè°ƒç”¨result_fnå‡½æ•°ï¼Œç›´åˆ°å‡½æ•°è¿”å›éNoneå€¼æˆ–è¶…æ—¶ã€‚
        
        å‚æ•°:
            result_fn: è¦æ‰§è¡Œçš„å‡½æ•°ï¼Œåº”è¿”å›Noneè¡¨ç¤ºç»§ç»­ç­‰å¾…ï¼ŒéNoneè¡¨ç¤ºå®Œæˆ
            interval: æ£€æŸ¥é—´éš”ï¼Œå•ä½ä¸ºç§’
            timeout: æœ€å¤§ç­‰å¾…æ—¶é—´ï¼Œå•ä½ä¸ºç§’
            
        è¿”å›:
            result_fnçš„è¿”å›å€¼ï¼Œå¦‚æœè¶…æ—¶åˆ™è¿”å›None
        """
        start_time = time.monotonic()
        while time.monotonic() - start_time < timeout:
            result = result_fn()
            if result is None:
                time.sleep(interval)
            else:
                break

        return result

    def train_stages(self, round_num, start_stage, is_coordinator):
        """
        æ‰§è¡Œç‰¹å®šè½®æ¬¡çš„è®­ç»ƒé˜¶æ®µ
        
        è¿™ä¸ªæ–¹æ³•æ˜¯è®­ç»ƒè¿‡ç¨‹çš„æ ¸å¿ƒï¼Œè´Ÿè´£æ‰§è¡Œä»start_stageå¼€å§‹çš„æ‰€æœ‰è®­ç»ƒé˜¶æ®µã€‚
        å¦‚æœæ˜¯åè°ƒè€…èŠ‚ç‚¹ï¼Œå®ƒè¿˜ä¼šå°†å½“å‰è½®æ¬¡å’Œé˜¶æ®µä¿¡æ¯å‘å¸ƒåˆ°DHTç½‘ç»œã€‚
        
        å‚æ•°:
            round_num: å½“å‰è®­ç»ƒè½®æ¬¡
            start_stage: å¼€å§‹çš„é˜¶æ®µç´¢å¼•
            is_coordinator: æ˜¯å¦ä¸ºåè°ƒè€…èŠ‚ç‚¹
        """
        # TODO: Needs checkpoint loading
        self.node.round_num = round_num
        for i, stage in enumerate(self.stage_data.stages[start_stage:]):
            stage_num = start_stage + i
            self.node.stage_num = stage_num

            if is_coordinator:
                # å¦‚æœæ˜¯åè°ƒè€…èŠ‚ç‚¹ï¼Œå°†å½“å‰è½®æ¬¡å’Œé˜¶æ®µä¿¡æ¯å‘å¸ƒåˆ°DHTç½‘ç»œ
                # è¿™æ˜¯ä¸€ä¸ªç½‘ç»œé€šä¿¡æ“ä½œï¼Œä½¿å…¶ä»–èŠ‚ç‚¹èƒ½å¤Ÿè·çŸ¥å½“å‰è®­ç»ƒè¿›åº¦
                self.dht.store(
                    key=ROUND_STAGE_NUMBER_KEY,
                    value=(self.node.round_num, stage_num),
                    expiration_time=get_dht_time() + self.node.out_expiration,
                )

            self.logger.info(f"ğŸ“ˆ è®­ç»ƒè½®æ¬¡: {round_num} é˜¶æ®µ: {stage_num}")
            # è·å–å½“å‰é˜¶æ®µçš„è®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†
            train_dataset, test_dataset = stage.datasets_fn(round_num, stage_num)
            # å‡†å¤‡è®­ç»ƒå™¨å‚æ•°
            kwargs = {
                "model": self.model,
                "args": self.config,
                "reward_funcs": stage.reward_funcs,  # å½“å‰é˜¶æ®µçš„å¥–åŠ±å‡½æ•°
                "train_dataset": train_dataset,
                "eval_dataset": test_dataset,
            }
            # åˆ›å»ºPublishingGRPOTrainerå®ä¾‹ï¼Œå®ƒä¼šå°†è®­ç»ƒç»“æœå‘å¸ƒåˆ°DHTç½‘ç»œ
            trainer = HivemindGRPOTrainer.PublishingGRPOTrainer(
                self.node, self.dht, self.tokenizer, self.logger, **kwargs
            )
            # æ‰§è¡Œè®­ç»ƒå¹¶ä¿å­˜æ¨¡å‹
            self.train_and_save(trainer, train_dataset)
            self.logger.info(
                f"ğŸ“‰ å®Œæˆè®­ç»ƒè½®æ¬¡: {round_num} é˜¶æ®µ: {stage_num}"
            )

        # Push to HF hub if desired
        # TODO: Come back and add additional logic checking if they've provided access token+HF username
        if self.config.push_to_hub_token is not None:
            self.logger.info("æ­£åœ¨å°†æ¨¡å‹æ¨é€åˆ° Hugging Face Hub...")
            try:
                trainer.push_to_hub(
                    tags=[
                        "rl-swarm",
                        "grpo",
                        "gensyn",
                        f"I am {get_name_from_peer_id(self.node.key)}",
                    ]
                )
                time.sleep(1)
            except Exception:
                self.logger.info(
                    "æ¨é€æ¨¡å‹åˆ° Hugging Face Hub å¤±è´¥ã€‚å½“æ‚¨å®Œæˆè®­ç»ƒåï¼Œè¯·å°è¯•æŒ‰ç…§ä»¥ä¸‹è¯´æ˜æ‰‹åŠ¨æ¨é€æ¨¡å‹ï¼šhttps://huggingface.co/docs/hub/en/models-uploading"
                )

        self.cleanup()

    def cleanup(self):
        """
        æ¸…ç†è®­ç»ƒèµ„æºå’Œç¼“å­˜
        
        è¿™ä¸ªæ–¹æ³•åœ¨è®­ç»ƒé˜¶æ®µå®Œæˆåè°ƒç”¨ï¼Œç”¨äºé‡Šæ”¾å†…å­˜å’Œæ¸…ç†ç¼“å­˜ï¼Œ
        åŒ…æ‹¬Pythonåƒåœ¾å›æ”¶ã€PyTorchç¼“å­˜æ¸…ç†å’ŒèŠ‚ç‚¹é˜¶æ®µç¼“å­˜æ¸…ç†ã€‚
        è¿™å¯¹äºé•¿æ—¶é—´è¿è¡Œçš„åˆ†å¸ƒå¼è®­ç»ƒç³»ç»Ÿéå¸¸é‡è¦ï¼Œå¯ä»¥é˜²æ­¢å†…å­˜æ³„æ¼ã€‚
        """
        # æ¸…ç†å„ç§é˜¶æ®µç¼“å­˜
        gc.collect()  # è§¦å‘Pythonåƒåœ¾å›æ”¶
        if torch.cuda.is_available():
            torch.cuda.empty_cache()  # æ¸…ç†CUDAç¼“å­˜
            torch.cuda.ipc_collect()  # æ¸…ç†CUDA IPCèµ„æº
        if torch.backends.mps.is_available():  # type: ignore
            torch.mps.empty_cache()  # type: ignore  # æ¸…ç†MPSç¼“å­˜ï¼ˆè‹¹æœMç³»åˆ—èŠ¯ç‰‡ï¼‰
        try:
            if torch.xpu.is_available():  # type: ignore
                torch.xpu.empty_cache()  # type: ignore  # æ¸…ç†XPUç¼“å­˜ï¼ˆIntel GPUï¼‰
        except AttributeError:
            pass

        # æ¸…ç†èŠ‚ç‚¹çš„é˜¶æ®µç¼“å­˜ï¼Œé‡Šæ”¾å­˜å‚¨çš„è¾“å‡ºå’Œå¥–åŠ±æ•°æ®
        self.node.clear_stage_cache()

    def train_and_save(self, trainer, train_dataset):
        """
        æ‰§è¡Œè®­ç»ƒå¹¶ä¿å­˜æ¨¡å‹å’ŒæŒ‡æ ‡
        
        è¿™ä¸ªæ–¹æ³•ä½¿ç”¨æä¾›çš„è®­ç»ƒå™¨æ‰§è¡Œè®­ç»ƒï¼Œç„¶åè®°å½•å’Œä¿å­˜è®­ç»ƒæŒ‡æ ‡ï¼Œ
        æœ€åä¿å­˜æ¨¡å‹å’Œåˆ†è¯å™¨ã€‚åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸­ï¼Œå®ƒè¿˜ä¼šç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®ŒæˆåŠ è½½ã€‚
        
        å‚æ•°:
            trainer: PublishingGRPOTrainerå®ä¾‹ï¼Œç”¨äºæ‰§è¡Œè®­ç»ƒ
            train_dataset: è®­ç»ƒæ•°æ®é›†ï¼Œç”¨äºè®¡ç®—æ ·æœ¬æ•°é‡
        """
        # æ‰§è¡Œè®­ç»ƒå¹¶è·å–ç»“æœ
        train_result = trainer.train()

        # è®°å½•å’Œä¿å­˜æŒ‡æ ‡
        metrics = train_result.metrics
        metrics["train_samples"] = len(train_dataset)  # æ·»åŠ è®­ç»ƒæ ·æœ¬æ•°é‡åˆ°æŒ‡æ ‡
        trainer.log_metrics("train", metrics)  # è®°å½•è®­ç»ƒæŒ‡æ ‡
        trainer.save_metrics("train", metrics)  # ä¿å­˜è®­ç»ƒæŒ‡æ ‡
        trainer.save_state()  # ä¿å­˜è®­ç»ƒå™¨çŠ¶æ€

        # ä¿å­˜æ¨¡å‹
        self.logger.info("æ­£åœ¨ä¿å­˜æ¨¡å‹")
        trainer.model.config.use_cache = True  # å¯ç”¨æ¨¡å‹ç¼“å­˜ä»¥æé«˜æ¨ç†æ€§èƒ½
        trainer.save_model(self.config.output_dir)  # ä¿å­˜æ¨¡å‹åˆ°è¾“å‡ºç›®å½•
        self.logger.info(f"æ¨¡å‹å·²ä¿å­˜åˆ° {self.config.output_dir}")
        
        # åœ¨åˆ†å¸ƒå¼ç¯å¢ƒä¸­ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ
        assert self.config.distributed_state
        self.config.distributed_state.wait_for_everyone()  # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹åŠ è½½å®Œæˆ

        # ä¿å­˜åˆ†è¯å™¨
        self.tokenizer.save_pretrained(self.config.output_dir)
        self.logger.info(f"åˆ†è¯å™¨å·²ä¿å­˜åˆ° {self.config.output_dir}")

    def get_round_and_stage(self):
        """
        è·å–å½“å‰çš„è½®æ¬¡å’Œé˜¶æ®µ
        
        è¿™ä¸ªæ–¹æ³•æ˜¯å¯¹dht_utils.get_round_and_stageçš„åŒ…è£…ï¼Œç”¨äºä»DHTç½‘ç»œè·å–
        å½“å‰çš„è®­ç»ƒè½®æ¬¡å’Œé˜¶æ®µä¿¡æ¯ã€‚è¿™äº›ä¿¡æ¯ç”±åè°ƒè€…èŠ‚ç‚¹å‘å¸ƒï¼Œæ‰€æœ‰è·Ÿéšè€…èŠ‚ç‚¹
        é€šè¿‡æ­¤æ–¹æ³•è·å–ä»¥åŒæ­¥è®­ç»ƒè¿›åº¦ã€‚
        
        è¿”å›:
            åŒ…å«è½®æ¬¡å·å’Œé˜¶æ®µå·çš„å…ƒç»„
            
        å¼‚å¸¸:
            ValueError: å¦‚æœæ— æ³•ä»DHTç½‘ç»œè·å–è½®æ¬¡å’Œé˜¶æ®µä¿¡æ¯
        """
        return get_round_and_stage(self.dht)

    def coordinator_train(self):
        """
        åè°ƒè€…èŠ‚ç‚¹çš„è®­ç»ƒå…¥å£
        
        è¿™ä¸ªæ–¹æ³•ç”±åè°ƒè€…èŠ‚ç‚¹è°ƒç”¨ï¼Œè´Ÿè´£ç®¡ç†æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ã€‚
        åè°ƒè€…èŠ‚ç‚¹ä»è½®æ¬¡0å¼€å§‹ï¼Œä¾æ¬¡æ‰§è¡Œæ¯ä¸ªè½®æ¬¡çš„æ‰€æœ‰é˜¶æ®µï¼Œå¹¶å°†è½®æ¬¡å’Œé˜¶æ®µä¿¡æ¯
        å‘å¸ƒåˆ°DHTç½‘ç»œï¼Œä½¿è·Ÿéšè€…èŠ‚ç‚¹èƒ½å¤ŸåŒæ­¥è®­ç»ƒè¿›åº¦ã€‚
        
        è®­ç»ƒä¼šåœ¨è¾¾åˆ°æœ€å¤§è½®æ¬¡æ•°æˆ–è¶…æ—¶æ—¶ç»“æŸã€‚
        """
        round_num = 0  # ä»è½®æ¬¡0å¼€å§‹
        start_time = time.monotonic()  # è®°å½•å¼€å§‹æ—¶é—´
        # åœ¨æœªè¾¾åˆ°æœ€å¤§è½®æ¬¡ä¸”æœªè¶…æ—¶çš„æƒ…å†µä¸‹ç»§ç»­è®­ç»ƒ
        while (
            round_num < self.stage_data.max_rounds
            and time.monotonic() - start_time < self.stage_data.train_timeout
        ):
            self.logger.info(f"ğŸ¤– å¼€å§‹æ–°çš„è®­ç»ƒè½®æ¬¡: {round_num}")

            # è·å–å¯è§çš„å¤šåœ°å€ï¼Œç¡®ä¿DHTç½‘ç»œè¿æ¥æ­£å¸¸
            _ = self.dht.get_visible_maddrs(latest=True)
            # æ‰§è¡Œå½“å‰è½®æ¬¡çš„æ‰€æœ‰é˜¶æ®µï¼Œä»é˜¶æ®µ0å¼€å§‹
            self.train_stages(round_num, 0, is_coordinator=True)

            # è½®æ¬¡å®Œæˆï¼Œå‡†å¤‡ä¸‹ä¸€è½®
            round_num += 1
            if round_num == self.stage_data.max_rounds:
                return  # è¾¾åˆ°æœ€å¤§è½®æ¬¡ï¼Œè®­ç»ƒç»“æŸ

        # å¦‚æœæ˜¯å› ä¸ºè¶…æ—¶è€Œé€€å‡ºå¾ªç¯ï¼Œè®°å½•æ—¥å¿—
        self.logger.info("è®­ç»ƒå·²è¶…æ—¶ï¼")

    def follower_train(
        self, check_interval=5.0, log_timeout=10.0, max_check_interval=30.0
    ):
        """
        è·Ÿéšè€…èŠ‚ç‚¹çš„è®­ç»ƒå…¥å£
        
        è¿™ä¸ªæ–¹æ³•ç”±è·Ÿéšè€…èŠ‚ç‚¹è°ƒç”¨ï¼Œè´Ÿè´£è·Ÿéšåè°ƒè€…èŠ‚ç‚¹çš„è®­ç»ƒè¿›åº¦ã€‚
        è·Ÿéšè€…èŠ‚ç‚¹å®šæœŸä»DHTç½‘ç»œè·å–å½“å‰çš„è½®æ¬¡å’Œé˜¶æ®µä¿¡æ¯ï¼Œç„¶åæ‰§è¡Œç›¸åº”çš„è®­ç»ƒé˜¶æ®µã€‚
        ä¸ºäº†é¿å…é‡å¤è®­ç»ƒï¼Œå®ƒä¼šè®°å½•å·²å®Œæˆçš„è½®æ¬¡ï¼Œå¹¶ä½¿ç”¨æŒ‡æ•°é€€é¿ç­–ç•¥å‡å°‘å¯¹å·²å®Œæˆè½®æ¬¡çš„æ£€æŸ¥é¢‘ç‡ã€‚
        
        å‚æ•°:
            check_interval: æ£€æŸ¥DHTç½‘ç»œçš„åˆå§‹é—´éš”ï¼Œå•ä½ä¸ºç§’
            log_timeout: æ—¥å¿—è®°å½•è¶…æ—¶ï¼Œé¿å…é¢‘ç¹è®°å½•ç›¸åŒé”™è¯¯
            max_check_interval: æœ€å¤§æ£€æŸ¥é—´éš”ï¼Œå•ä½ä¸ºç§’ï¼Œç”¨äºæŒ‡æ•°é€€é¿ç­–ç•¥
        """
        done_rounds = set()  # è®°å½•å·²å®Œæˆçš„è½®æ¬¡
        start_time = time.monotonic()  # è®°å½•å¼€å§‹æ—¶é—´
        fetch_log_time = start_time  # ä¸Šæ¬¡è·å–æ—¥å¿—çš„æ—¶é—´
        check_backoff = check_interval  # æ£€æŸ¥é—´éš”ï¼Œç”¨äºå·²å®Œæˆè½®æ¬¡çš„æŒ‡æ•°é€€é¿
        
        # åœ¨æœªè¶…æ—¶çš„æƒ…å†µä¸‹ç»§ç»­è®­ç»ƒ
        while time.monotonic() - start_time < self.stage_data.train_timeout:
            curr_time = time.monotonic()
            # è·å–å¯è§çš„å¤šåœ°å€ï¼Œç¡®ä¿DHTç½‘ç»œè¿æ¥æ­£å¸¸
            _ = self.dht.get_visible_maddrs(latest=True)

            # ä»DHTç½‘ç»œè·å–å½“å‰è½®æ¬¡å’Œé˜¶æ®µ
            try:
                round_num, stage = self.get_round_and_stage()
            except Exception as e:
                # å¦‚æœæ— æ³•è·å–è½®æ¬¡å’Œé˜¶æ®µä¿¡æ¯ï¼Œè®°å½•æ—¥å¿—å¹¶ç»§ç»­å°è¯•
                if curr_time - fetch_log_time > log_timeout:
                    self.logger.debug(
                        f"æ— æ³•è·å–è½®æ¬¡å’Œé˜¶æ®µä¿¡æ¯: {e}ã€‚å°†åœ¨ {check_interval}ç§’ åé‡æ–°æ£€æŸ¥ã€‚"
                    )
                    fetch_log_time = curr_time

                time.sleep(check_interval)
                continue

            # å¦‚æœæ˜¯æ–°çš„è½®æ¬¡ï¼ˆæœªå®Œæˆï¼‰ï¼Œåˆ™å¼€å§‹è®­ç»ƒ
            if round_num not in done_rounds:
                self.logger.info(
                    f"ğŸ åŠ å…¥è®­ç»ƒè½®æ¬¡: {round_num} ä»é˜¶æ®µ: {stage} å¼€å§‹"
                )
                try:
                    # ä»å½“å‰é˜¶æ®µå¼€å§‹è®­ç»ƒ
                    self.train_stages(round_num, stage, is_coordinator=False)
                except datasets.exceptions.DatasetGenerationError:
                    # å¦‚æœæ•°æ®é›†ç”Ÿæˆé”™è¯¯ä¸”ä¸æ˜¯ç¬¬ä¸€é˜¶æ®µï¼Œå°è¯•ä»é˜¶æ®µ0é‡æ–°å¼€å§‹
                    if stage > 0:
                        self.logger.info("æ­£åœ¨ä»é˜¶æ®µ0é‡æ–°å¼€å§‹è®­ç»ƒï¼")

                        # ä»é˜¶æ®µ0é‡æ–°å¼€å§‹
                        self.train_stages(round_num, 0, is_coordinator=False)
                    else:
                        raise  # å¦‚æœæ˜¯ç¬¬ä¸€é˜¶æ®µå‡ºé”™ï¼Œåˆ™æŠ›å‡ºå¼‚å¸¸

                # æ ‡è®°è½®æ¬¡ä¸ºå·²å®Œæˆ
                done_rounds.add(round_num)
                check_backoff = check_interval  # é‡ç½®é€€é¿é—´éš”
            else:
                # å¦‚æœè½®æ¬¡å·²å®Œæˆï¼Œä½¿ç”¨æŒ‡æ•°é€€é¿ç­–ç•¥å‡å°‘æ£€æŸ¥é¢‘ç‡
                if check_backoff != 30:
                    self.logger.info(
                        f":{self.node.key}:å·²å®Œæˆè®­ç»ƒè½®æ¬¡: {round_num}ã€‚å°†åœ¨ {check_backoff}ç§’ åé‡æ–°æ£€æŸ¥æ˜¯å¦æœ‰æ–°ä»»åŠ¡ï¼Œæ—¥å¿—æš‚åœåˆ·æ–°ï¼Œä¸æ˜¯å¡ä½ï¼Œè€å¿ƒç­‰å¾…ã€‚"
                    )
                time.sleep(check_backoff)
                # æŒ‡æ•°é€€é¿ï¼šå°†æ£€æŸ¥é—´éš”ç¿»å€ï¼Œä½†ä¸è¶…è¿‡æœ€å¤§é—´éš”
                check_backoff = min(check_backoff * 2, max_check_interval)

            # å¦‚æœè¾¾åˆ°æœ€åä¸€è½®ï¼Œè®­ç»ƒç»“æŸ
            if round_num == self.stage_data.max_rounds - 1:
                return

        # å¦‚æœæ˜¯å› ä¸ºè¶…æ—¶è€Œé€€å‡ºå¾ªç¯ï¼Œè®°å½•æ—¥å¿—
        self.logger.info("è®­ç»ƒå·²è¶…æ—¶ï¼")

    def train(self):
        """
        è®­ç»ƒå…¥å£æ–¹æ³•
        
        è¿™æ˜¯HivemindGRPOTrainerç±»çš„ä¸»è¦å…¥å£æ–¹æ³•ï¼Œæ ¹æ®èŠ‚ç‚¹ç±»å‹ï¼ˆåè°ƒè€…æˆ–è·Ÿéšè€…ï¼‰
        è°ƒç”¨ä¸åŒçš„è®­ç»ƒæµç¨‹ã€‚åè°ƒè€…èŠ‚ç‚¹è´Ÿè´£ç®¡ç†æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ï¼Œè€Œè·Ÿéšè€…èŠ‚ç‚¹åˆ™è·Ÿéš
        åè°ƒè€…çš„è¿›åº¦è¿›è¡Œè®­ç»ƒã€‚
        
        è¯¥æ–¹æ³•æ•è·å¹¶æ‰“å°æ‰€æœ‰å¼‚å¸¸ï¼Œç¡®ä¿è®­ç»ƒè¿‡ç¨‹ä¸­çš„é”™è¯¯ä¸ä¼šå¯¼è‡´æ•´ä¸ªç¨‹åºå´©æºƒã€‚
        """
        try:
            # æ ¹æ®èŠ‚ç‚¹ç±»å‹é€‰æ‹©ä¸åŒçš„è®­ç»ƒæµç¨‹
            if self.node.is_coordinator:
                # åè°ƒè€…èŠ‚ç‚¹ï¼šç®¡ç†è®­ç»ƒè¿›åº¦ï¼Œå‘å¸ƒè½®æ¬¡å’Œé˜¶æ®µä¿¡æ¯
                self.coordinator_train()
            else:
                # è·Ÿéšè€…èŠ‚ç‚¹ï¼šè·Ÿéšåè°ƒè€…çš„è¿›åº¦è¿›è¡Œè®­ç»ƒ
                self.follower_train()

        except Exception:
            # æ•è·å¹¶æ‰“å°æ‰€æœ‰å¼‚å¸¸ï¼Œç¡®ä¿è®­ç»ƒè¿‡ç¨‹ä¸­çš„é”™è¯¯ä¸ä¼šå¯¼è‡´ç¨‹åºå´©æºƒ
            import traceback

            traceback.print_exc()
