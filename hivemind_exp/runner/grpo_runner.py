import logging
from dataclasses import dataclass, field
from datetime import datetime
from typing import Callable, Tuple

# å¯¼å…¥hivemindåº“ï¼Œç”¨äºåˆ›å»ºå’Œç®¡ç†åˆ†å¸ƒå¼å“ˆå¸Œè¡¨(DHT)ç½‘ç»œ
import hivemind
from datasets import Dataset
from huggingface_hub import login
from transformers import AutoModelForCausalLM, AutoTokenizer
from trl import GRPOConfig, ModelConfig

from hivemind_exp.gsm8k.stage_utils import gsm8k_stage_data
from hivemind_exp.hivemind_utils import HivemindNode
from hivemind_exp.name_utils import get_name_from_peer_id
from hivemind_exp.trainer.hivemind_grpo_trainer import HivemindGRPOTrainer

# åˆ›å»ºæ—¥å¿—è®°å½•å™¨
logger = logging.getLogger(__name__)

@dataclass
class GRPOArguments:
    # Hivemindå‚æ•°
    initial_peers: list[str] = field(default_factory=list)  # åˆå§‹å¯¹ç­‰èŠ‚ç‚¹åˆ—è¡¨ï¼Œç”¨äºåŠ å…¥ç°æœ‰çš„DHTç½‘ç»œ
    public_maddr: str | None = None  # å…¬å…±å¤šåœ°å€ï¼Œç”¨äºå‘å…¶ä»–èŠ‚ç‚¹å®£å‘Šè‡ªå·±çš„å­˜åœ¨
    host_maddr: str | None = None  # ä¸»æœºå¤šåœ°å€ï¼Œç”¨äºç›‘å¬è¿æ¥
    identity_path: str | None = None  # èº«ä»½æ–‡ä»¶è·¯å¾„ï¼Œç”¨äºæŒä¹…åŒ–èŠ‚ç‚¹èº«ä»½
    max_rounds: int = 100  # æœ€å¤§è®­ç»ƒè½®æ¬¡æ•°

    # æ¨¡å‹å‚æ•°
    dataset_id_or_path: str = "openai/gsm8k"  # æ•°æ®é›†IDæˆ–è·¯å¾„
    dataset_splits: str = "train"  # æ•°æ®é›†åˆ†å‰²
    tokenizer_name_or_path: str | None = None  # åˆ†è¯å™¨åç§°æˆ–è·¯å¾„
    number_of_data_samples: int = 50000  # æ•°æ®æ ·æœ¬æ•°é‡
    public_maddr: str | None = None  # å…¬å…±å¤šåœ°å€ï¼ˆé‡å¤å®šä¹‰ï¼‰

    # Hugging Face Hubå‚æ•°
    hf_token: str | None = None  # Hugging Faceçš„è®¿é—®ä»¤ç‰Œ


class GRPORunner:
    def get_model(self, args: GRPOConfig, model_name: str):
        """è·å–é¢„è®­ç»ƒçš„å› æœè¯­è¨€æ¨¡å‹
        
        å‚æ•°:
            args: GRPOé…ç½®
            model_name: æ¨¡å‹åç§°æˆ–è·¯å¾„
            
        è¿”å›:
            åŠ è½½çš„æ¨¡å‹å®ä¾‹
        """
        model_init_kwargs = args.model_init_kwargs or {}
        # å¦‚æœå¯ç”¨äº†æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼Œåˆ™ç¦ç”¨ç¼“å­˜ï¼ˆä¸æ”¯æŒï¼‰
        model_init_kwargs["use_cache"] = (
            False if args.gradient_checkpointing else model_init_kwargs.get("use_cache")
        )
        return AutoModelForCausalLM.from_pretrained(model_name, **model_init_kwargs)

    def get_tokenizer_name(self, model_args: ModelConfig, script_args: GRPOArguments):
        """è·å–åˆ†è¯å™¨åç§°
        
        å‚æ•°:
            model_args: æ¨¡å‹é…ç½®
            script_args: GRPOå‚æ•°
            
        è¿”å›:
            åˆ†è¯å™¨åç§°æˆ–è·¯å¾„
            
        å¼‚å¸¸:
            ValueError: å¦‚æœæ— æ³•è§£æåˆ†è¯å™¨åç§°
        """
        if script_args.tokenizer_name_or_path:
            return script_args.tokenizer_name_or_path
        if model_args.model_name_or_path:
            return model_args.model_name_or_path
        raise ValueError("æ— æ³•è§£æåˆ†è¯å™¨åç§°")

    def _dht_kwargs(self, grpo_args):
        """
        æ„å»ºDHTåˆå§‹åŒ–æ‰€éœ€çš„å…³é”®å­—å‚æ•°
        
        å‚æ•°:
            grpo_args: GRPOå‚æ•°
            
        è¿”å›:
            åŒ…å«DHTåˆå§‹åŒ–å‚æ•°çš„å­—å…¸
        """
        kwargs = {}
        initial_peers = grpo_args.initial_peers
        if initial_peers:
            # è®¾ç½®åˆå§‹å¯¹ç­‰èŠ‚ç‚¹ï¼Œç”¨äºåŠ å…¥ç°æœ‰çš„DHTç½‘ç»œ
            kwargs["initial_peers"] = initial_peers

        if public_maddr := grpo_args.public_maddr:
            # è®¾ç½®å…¬å‘Šåœ°å€ï¼Œç”¨äºå‘å…¶ä»–èŠ‚ç‚¹å®£å‘Šè‡ªå·±çš„å­˜åœ¨
            kwargs["announce_maddrs"] = [public_maddr]

        if host_maddr := grpo_args.host_maddr:
            # è®¾ç½®ä¸»æœºåœ°å€ï¼Œç”¨äºç›‘å¬è¿æ¥
            kwargs["host_maddrs"] = [host_maddr]

        if identity_path := grpo_args.identity_path:
            # è®¾ç½®èº«ä»½æ–‡ä»¶è·¯å¾„ï¼Œç”¨äºæŒä¹…åŒ–èŠ‚ç‚¹èº«ä»½
            kwargs["identity_path"] = identity_path

        return kwargs

    def _get_animal_name(self, peer_id):
        """
        æ ¹æ®èŠ‚ç‚¹IDç”Ÿæˆå‹å¥½çš„åŠ¨ç‰©åç§°
        
        å‚æ•°:
            peer_id: èŠ‚ç‚¹ID
            
        è¿”å›:
            ç”Ÿæˆçš„åŠ¨ç‰©åç§°
        """
        animal_name = get_name_from_peer_id(peer_id)
        logger.info(f"ğŸ± ä½ å¥½ ğŸˆ [{animal_name}] ğŸ¦® [{peer_id}]!")
        return animal_name

    def setup_dht(self, grpo_args):
        """
        è®¾ç½®å¹¶å¯åŠ¨DHTç½‘ç»œè¿æ¥
        
        å‚æ•°:
            grpo_args: GRPOå‚æ•°ï¼ŒåŒ…å«åˆå§‹å¯¹ç­‰èŠ‚ç‚¹ç­‰ç½‘ç»œé…ç½®
            
        è¿”å›:
            åˆå§‹åŒ–å¹¶å¯åŠ¨çš„DHTå®ä¾‹
        """
        initial_peers = grpo_args.initial_peers
        # åˆ›å»ºå¹¶å¯åŠ¨DHTå®ä¾‹ï¼Œä½¿ç”¨_dht_kwargsæ–¹æ³•æ„å»ºå‚æ•°
        dht = hivemind.DHT(start=True, **self._dht_kwargs(grpo_args))
        
        # æ ¹æ®æ˜¯å¦æœ‰åˆå§‹å¯¹ç­‰èŠ‚ç‚¹ï¼Œå†³å®šæ˜¯åŠ å…¥ç°æœ‰ç½‘ç»œè¿˜æ˜¯åˆ›å»ºæ–°ç½‘ç»œ
        if initial_peers:
            # æœ‰åˆå§‹å¯¹ç­‰èŠ‚ç‚¹ï¼ŒåŠ å…¥ç°æœ‰çš„èœ‚ç¾¤ç½‘ç»œ
            logger.info(f"ğŸ æ­£åœ¨åŠ å…¥èœ‚ç¾¤ç½‘ç»œï¼Œåˆå§‹å¯¹ç­‰èŠ‚ç‚¹ = {initial_peers}")
        else:
            # æ²¡æœ‰åˆå§‹å¯¹ç­‰èŠ‚ç‚¹ï¼Œåˆ›å»ºæ–°çš„èœ‚ç¾¤ç½‘ç»œ
            first_visible = str(dht.get_visible_maddrs()[0])
            logger.info(f"ğŸ¤– æ­£åœ¨å¯åŠ¨èœ‚ç¾¤ç½‘ç»œï¼Œåœ°å€ä¸º {first_visible}")

        # æ ¹æ®èŠ‚ç‚¹IDç”Ÿæˆå‹å¥½çš„åŠ¨ç‰©åç§°
        self.name = self._get_animal_name(str(dht.peer_id))
        return dht

    def run(
        self,
        model_args: ModelConfig,
        grpo_args: GRPOArguments,
        training_args: GRPOConfig,
        initial_datasets_fn: Callable[[], Tuple[Dataset, Dataset]],
        trainer_factory_fn: Callable = HivemindGRPOTrainer,
    ):
        """
        è¿è¡ŒGRPOè®­ç»ƒæµç¨‹çš„ä¸»æ–¹æ³•
        
        å‚æ•°:
            model_args: æ¨¡å‹é…ç½®å‚æ•°
            grpo_args: GRPOç®—æ³•å‚æ•°
            training_args: è®­ç»ƒé…ç½®å‚æ•°
            initial_datasets_fn: è·å–åˆå§‹æ•°æ®é›†çš„å‡½æ•°
            trainer_factory_fn: åˆ›å»ºè®­ç»ƒå™¨çš„å·¥å‚å‡½æ•°
        """
        #########################
        # è®°å½•å‚æ•°
        #########################
        logger.debug(f"æ¨¡å‹å‚æ•° {model_args}")
        logger.debug(f"è®­ç»ƒ/è¯„ä¼°å‚æ•° {training_args}")

        # è®¾ç½®æ‰¹å¤„ç†å¤§å°
        batch_size = 2
        training_args.per_device_train_batch_size = batch_size
        training_args.num_generations = batch_size

        ############################
        # å¦‚æœéœ€è¦ï¼Œç™»å½•Hugging Face Hub
        ############################
        if (grpo_args.hf_token not in [None, "None"]):
            training_args.push_to_hub_token = grpo_args.hf_token
            login(token=training_args.push_to_hub_token, add_to_git_credential=True)
        else:
            training_args.push_to_hub_token = None

        ################
        # åŠ è½½åˆ†è¯å™¨
        ################
        tokenizer = AutoTokenizer.from_pretrained(
            self.get_tokenizer_name(model_args, grpo_args),
            revision=model_args.model_revision,
            trust_remote_code=model_args.trust_remote_code,
        )
        # å¦‚æœæ²¡æœ‰å¡«å……æ ‡è®°ï¼Œä½¿ç”¨ç»“æŸæ ‡è®°ä½œä¸ºå¡«å……æ ‡è®°
        if tokenizer.pad_token is None:
            tokenizer.pad_token = tokenizer.eos_token

        #########################
        # é€šè¿‡Hivemindåˆ›å»ºDHTç½‘ç»œ
        #########################
        dht = self.setup_dht(grpo_args)

        #####################################
        # åŠ è½½æ•°æ®é›†ï¼Œå‡†å¤‡å’Œæ ¼å¼åŒ–
        #####################################
        train_dataset, test_dataset = initial_datasets_fn()

        #########################
        # å®ä¾‹åŒ–GRPOè®­ç»ƒå™¨
        #########################
        model_name_or_path = model_args.model_name_or_path
        assert model_name_or_path
        # åŠ è½½æ¨¡å‹
        model = self.get_model(training_args, model_name_or_path)

        # æ ¹æ®æ˜¯å¦æœ‰åˆå§‹å¯¹ç­‰èŠ‚ç‚¹ï¼Œå†³å®šæ˜¯åˆ›å»ºæ™®é€šèŠ‚ç‚¹è¿˜æ˜¯åè°ƒè€…èŠ‚ç‚¹
        initial_peers = grpo_args.initial_peers
        if initial_peers:
            # æœ‰åˆå§‹å¯¹ç­‰èŠ‚ç‚¹ï¼Œåˆ›å»ºæ™®é€šèŠ‚ç‚¹
            node = HivemindNode(model_name_or_path, str(dht.peer_id))
        else:
            # æ²¡æœ‰åˆå§‹å¯¹ç­‰èŠ‚ç‚¹ï¼Œåˆ›å»ºåè°ƒè€…èŠ‚ç‚¹
            node = HivemindNode.coordinator(model_name_or_path, str(dht.peer_id))

        # åˆ›å»ºè®­ç»ƒé˜¶æ®µæ•°æ®
        stage_data = gsm8k_stage_data(dht, node, train_dataset, test_dataset)
        stage_data.max_rounds = grpo_args.max_rounds
        
        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = trainer_factory_fn(
            dht=dht,  # DHTç½‘ç»œå®ä¾‹
            node=node,  # HivemindèŠ‚ç‚¹
            model=model,  # æ¨¡å‹
            tokenizer=tokenizer,  # åˆ†è¯å™¨
            config=training_args,  # è®­ç»ƒé…ç½®
            stage_data=stage_data,  # è®­ç»ƒé˜¶æ®µæ•°æ®
            log_tag=self.name,  # æ—¥å¿—æ ‡ç­¾
        )

        ###############
        # è®­ç»ƒå¾ªç¯
        ###############
        logger.info(
            f"å¼€å§‹è®­ç»ƒ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}ï¼Œå…± {training_args.num_train_epochs} ä¸ªè®­ç»ƒå‘¨æœŸ"
        )
        # å¼€å§‹è®­ç»ƒ
        trainer.train()
